{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be808a3c-eefb-499f-b841-fae005e01b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec0c6067-16d9-412d-bc93-a6999551dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8bf23b0-5eff-49b3-895e-cf899cd10b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder:\n",
    "    def __init__(self, vocab_size, seq_len, emb_dim, linear_layers_hidden_dim, ffn_hiiden_dim):\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.linear_layers_hidden_dim = linear_layers_hidden_dim\n",
    "        self.ffn_hiiden_dim = ffn_hiiden_dim\n",
    "\n",
    " \n",
    "    def get_sin_output(self, pos):\n",
    "        t = tf.multiply(tf.constant(2, dtype=tf.float32), tf.range(0, self.emb_dim, dtype=tf.float32))\n",
    "        t1 = tf.pow(tf.constant(10000, dtype=tf.float32), tf.divide(t, self.emb_dim))\n",
    "        position_tensor = tf.fill([1, self.emb_dim], pos)\n",
    "        sin_fun_input = tf.divide(position_tensor, t1)\n",
    "        output = tf.sin(sin_fun_input)\n",
    "        return output\n",
    "    \n",
    "    def get_cos_output(self, pos):\n",
    "        t = tf.multiply(tf.constant(2, dtype=tf.float32), tf.range(0, self.emb_dim, dtype=tf.float32))\n",
    "        t1 = tf.pow(tf.constant(10000, dtype=tf.float32), tf.divide(t, self.emb_dim))\n",
    "        position_tensor = tf.fill([1, self.emb_dim], pos)\n",
    "        sin_fun_input = tf.divide(position_tensor, t1)\n",
    "        output = tf.cos(sin_fun_input)\n",
    "        return output\n",
    "    \n",
    "    def call(self, X):\n",
    "\n",
    "        # X is data such as [[hello, world],[amazing, code]]. It is in the format of int32       \n",
    "        # first embedding layer\n",
    "        # start of embedding graph\n",
    "        first_inputs = tf.compat.v1.placeholder(dtype=tf.float32, shape=(None, self.seq_len), name='firstInputPlaceholder')\n",
    "        one_hot_encoded = tf.one_hot(first_inputs, dtype=tf.float32, depth=self.vocab_size)\n",
    "        inputs = tf.compat.v1.placeholder(dtype=tf.float32, shape=(1, self.vocab_size), name='InputPlaceholder')\n",
    "        input_pos = tf.compat.v1.placeholder_with_default(0.0, shape=(), name='input_pos')\n",
    "        w1 = tf.Variable(tf.random.normal(shape=(self.vocab_size, self.emb_dim), dtype=tf.float32), name='w1')\n",
    "        b1 = tf.Variable(tf.constant(0.1, shape=(1, self.emb_dim), dtype=tf.float32), name='b1')\n",
    "        y1 = tf.add(tf.matmul(inputs, w1), b1)\n",
    "        # end of embedding graph\n",
    "\n",
    "        #positional embeddings \n",
    "        @tf.function\n",
    "        def conditoinal(pos):\n",
    "            if tf.equal(tf.experimental.numpy.mod(pos,2) ,0):\n",
    "                return self.get_sin_output(pos)\n",
    "            return self.get_cos_output(pos)\n",
    "\n",
    "        positional_out = tf.add(conditoinal(input_pos), y1)\n",
    "        # end of positional output\n",
    "\n",
    "\n",
    "        #value linear layer\n",
    "        inputs_v = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.emb_dim), name='linear_layer_graph_placeholder_v')\n",
    "        w1_v = tf.Variable(tf.random.normal(shape=(self.emb_dim, self.linear_layers_hidden_dim), dtype=tf.float32), name='w1_v')\n",
    "        b1_v = tf.Variable(tf.constant(0.1, shape=(1, self.linear_layers_hidden_dim), dtype=tf.float32), name='b1_v')\n",
    "        y1_v = tf.add(tf.matmul(inputs_v, w1_v), b1_v)\n",
    "\n",
    "        #key linear layer\n",
    "        inputs_k = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.emb_dim), name='linear_layer_graph_placeholder_k')\n",
    "        w1_k = tf.Variable(tf.random.normal(shape=(self.emb_dim, self.linear_layers_hidden_dim), dtype=tf.float32), name='w1_k')\n",
    "        b1_k = tf.Variable(tf.constant(0.1, shape=(1, self.linear_layers_hidden_dim), dtype=tf.float32), name='b1_k')\n",
    "        y1_k = tf.add(tf.matmul(inputs_k, w1_k), b1_k)\n",
    "\n",
    "        #query linear layer\n",
    "        inputs_q = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.emb_dim), name='linear_layer_graph_placeholder_q')\n",
    "        w1_q = tf.Variable(tf.random.normal(shape=(self.emb_dim, self.linear_layers_hidden_dim), dtype=tf.float32), name='w1_q')\n",
    "        b1_q = tf.Variable(tf.constant(0.1, shape=(1, self.linear_layers_hidden_dim), dtype=tf.float32), name='b1_q')\n",
    "        y1_q = tf.add(tf.matmul(inputs_q, w1_q), b1_q)\n",
    "\n",
    "\n",
    "        transposed_key_mat = tf.transpose(y1_k, name='key_transpose_op')\n",
    "        attention_filter = tf.divide(tf.matmul(y1_q, transposed_key_mat), tf.sqrt(tf.constant(self.emb_dim, dtype=tf.float32)), name='attention_filter')\n",
    "        softmaxed_attention_filter = tf.nn.softmax(attention_filter, name='softmax_of_attention_filter')\n",
    "        final_output_of_one_head = tf.matmul(softmaxed_attention_filter, y1_v, name='final_matmul')\n",
    "        print(final_output_of_one_head)\n",
    "        # final linear layer\n",
    "        inputs_final = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.linear_layers_hidden_dim), name='linear_layer_graph_placeholder_final')\n",
    "        w1_final = tf.Variable(tf.random.normal(shape=(self.linear_layers_hidden_dim, self.emb_dim), dtype=tf.float32), name='w1_final')\n",
    "        b1_final = tf.Variable(tf.constant(0.1, shape=(1, self.emb_dim), dtype=tf.float32), name='b1_final')\n",
    "        y1_final = tf.add(tf.matmul(inputs_final, w1_final), b1_final)\n",
    "\n",
    "        #here multhead attention finishes\n",
    "\n",
    "        # now onto add and norm layer\n",
    "        inputs_for_norm = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.emb_dim), name='InputPlaceholderNorm')\n",
    "        add_op = tf.add(inputs_for_norm,y1_final)\n",
    "        meaned_output = tf.reduce_mean(y1_final, axis=1)\n",
    "        std_output = tf.math.reduce_std(y1_final, axis=0)\n",
    "        x0 = tf.transpose(tf.subtract(tf.transpose(add_op), meaned_output))\n",
    "        divisor = tf.sqrt(tf.add(std_output, tf.constant(0.001, dtype=tf.float32)))\n",
    "        res = tf.divide(x0, divisor)\n",
    "        # finsish add and norm layer\n",
    "        print(res)\n",
    "        #feed forward network\n",
    "        inputs_for_ffn = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.emb_dim), name='InputPlaceholderLinear')\n",
    "        w1_ffn = tf.Variable(tf.random.normal(shape=(self.emb_dim, self.ffn_hiiden_dim), dtype=tf.float32), name='w1_ffn')\n",
    "        b1_ffn = tf.Variable(tf.constant(0.1, shape=(1, self.ffn_hiiden_dim), dtype=tf.float32), name='b1_ffn')\n",
    "        y1_ffn = tf.nn.relu(tf.add(tf.matmul(inputs_for_ffn, w1_ffn), b1_ffn))\n",
    "        w2_ffn = tf.Variable(tf.random.normal(shape=(self.ffn_hiiden_dim, self.emb_dim), dtype=tf.float32), name='w2_ffn')\n",
    "        b2_ffn = tf.Variable(tf.constant(0.1, shape=(1, self.emb_dim), dtype=tf.float32), name='b2_ffn')\n",
    "        y2_ffn = tf.add(tf.matmul(y1_ffn, w2_ffn), b2_ffn)\n",
    "        #end of feed forward neural network\n",
    "\n",
    "        #now onto final add and norm layer\n",
    "        inputs_for_norm_final = tf.compat.v1.placeholder(dtype=tf.float32, shape=(self.seq_len, self.emb_dim), name='InputPlaceholderLinear')\n",
    "        add_op_final = tf.add(inputs_for_norm_final,y2_ffn)\n",
    "        meaned_output_final = tf.reduce_mean(y2_ffn, axis=1)\n",
    "        std_output_final = tf.math.reduce_std(y2_ffn, axis=0)\n",
    "        x0_final = tf.transpose(tf.subtract(tf.transpose(add_op_final), meaned_output_final))\n",
    "        divisor_final = tf.sqrt(tf.add(std_output_final, tf.constant(0.001, dtype=tf.float32)))\n",
    "        res_final = tf.divide(x0_final, divisor_final)\n",
    "\n",
    "        return res_final\n",
    "            #driver code\n",
    "            \n",
    "            \n",
    "#             init_op = tf.compat.v1.global_variables_initializer()\n",
    "#             attention_head.run(init_op)\n",
    "            \n",
    "#             sentences = []\n",
    "#             final_output = []\n",
    "            \n",
    "#             for sent in X:\n",
    "#                 one_hot_encoded = tf.one_hot(sent, dtype=tf.float32, depth=self.vocab_size)\n",
    "#                 sent_vector = []\n",
    "#                 for pos,word in enumerate(tf.unstack(one_hot_encoded)):\n",
    "#                     word = tf.reshape(word, shape=(1,self.vocab_size)).eval(session=attention_head)\n",
    "#                     output_1 = positional_out.eval(session=attention_head, feed_dict={inputs:word, input_pos:pos})\n",
    "#                     sent_vector.append(output_1)\n",
    "#                 sent_vector = np.asarray(sent_vector).reshape((self.seq_len,self.emb_dim))\n",
    "#                 output_2 = final_output_of_one_head.eval(session=attention_head, feed_dict={inputs_k:sent_vector, inputs_q:sent_vector, inputs_v:sent_vector})\n",
    "#                 output_3 = res.eval(session=attention_head, feed_dict={inputs_final:output_2, inputs_for_norm:sent_vector})\n",
    "#                 output_4 = res_final.eval(session=attention_head, feed_dict={inputs_for_ffn:output_3, inputs_for_norm_final:output_3})\n",
    "#                 sentences.append(output_4)\n",
    "#             final_output.append(sentences)\n",
    "#             return np.asarray(final_output).reshape(len(final_output[0]), self.seq_len, self.emb_dim)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5231b0a-db34-4e3d-9006-482ef12f7e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_block = TransformerEncoder(vocab_size=len(vocab),\n",
    "        seq_len=20,\n",
    "        emb_dim=128,\n",
    "        linear_layers_hidden_dim = 128,\n",
    "        ffn_hiiden_dim = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "986f3a46-7fd6-4489-82d5-9490c17f9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "init_op = tf.compat.v1.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f13e7c8-ce5d-4143-afee-280536b174f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[[0, 1, 2, 3, 4],\n",
    "[5, 1, 2, 3, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6429b5c6-1d1d-4dc3-aa0f-be7ca5e27541",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument `fetch` = <__main__.TransformerEncoder object at 0x000001F0FE975460> has invalid type \"TransformerEncoder\" must be a string or Tensor. (Can not convert a TransformerEncoder into a Tensor or Operation.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\client\\session.py:304\u001b[0m, in \u001b[0;36m_ElementFetchMapper.__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unique_fetches\u001b[38;5;241m.\u001b[39mappend(\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_graph_element\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3998\u001b[0m, in \u001b[0;36mGraph.as_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3998\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_graph_element_locked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_operation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4086\u001b[0m, in \u001b[0;36mGraph._as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   4084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4085\u001b[0m   \u001b[38;5;66;03m# We give up!\u001b[39;00m\n\u001b[1;32m-> 4086\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not convert a \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m into a \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   4087\u001b[0m                   (\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, types_str))\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a TransformerEncoder into a Tensor or Operation.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\client\\session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1176\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       feed_map[compat\u001b[38;5;241m.\u001b[39mas_bytes(subfeed_t\u001b[38;5;241m.\u001b[39mname)] \u001b[38;5;241m=\u001b[39m (subfeed_t, subfeed_val)\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;66;03m# Create a fetch handler to take care of the structure of fetches.\u001b[39;00m\n\u001b[1;32m-> 1176\u001b[0m fetch_handler \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchHandler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_handles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed_handles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;66;03m# Run request and get response.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;66;03m# We need to keep the returned movers alive for the following _do_run().\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;66;03m# These movers are no longer needed when _do_run() completes, and\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;66;03m# are deleted when `movers` goes out of scope when this _run() ends.\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;66;03m# TODO(yuanbyu, keveman): Revisit whether we should just treat feeding\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;66;03m# of a handle from a different device as an error.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_with_movers(feed_dict_tensor, feed_map)\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\client\\session.py:485\u001b[0m, in \u001b[0;36m_FetchHandler.__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a fetch handler.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \n\u001b[0;32m    475\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    direct feeds.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m--> 485\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_mapper \u001b[38;5;241m=\u001b[39m \u001b[43m_FetchMapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_targets \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\client\\session.py:276\u001b[0m, in \u001b[0;36m_FetchMapper.for_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fetch, tensor_type):\n\u001b[0;32m    275\u001b[0m       fetches, contraction_fn \u001b[38;5;241m=\u001b[39m fetch_fn(fetch)\n\u001b[1;32m--> 276\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ElementFetchMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontraction_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# Did not find anything.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    279\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fetch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Transformers Implementation\\English to Hindi\\transformers\\lib\\site-packages\\tensorflow\\python\\client\\session.py:307\u001b[0m, in \u001b[0;36m_ElementFetchMapper.__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unique_fetches\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39mas_graph_element(\n\u001b[0;32m    305\u001b[0m       fetch, allow_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_operation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 307\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has invalid type \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    308\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(fetch)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m must be a string or Tensor. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    309\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    311\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgument `fetch` = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfetch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be interpreted as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    312\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma Tensor. (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument `fetch` = <__main__.TransformerEncoder object at 0x000001F0FE975460> has invalid type \"TransformerEncoder\" must be a string or Tensor. (Can not convert a TransformerEncoder into a Tensor or Operation.)"
     ]
    }
   ],
   "source": [
    "sess.run(transformer_block, feed_dict={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e78d8f1a-9dd7-4132-b719-8dccf100d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bert_vocab_uncased.txt', 'r') as f:\n",
    "    vocab_ = f.read()\n",
    "    vocab = {}\n",
    "    for i in (vocab_.split()):\n",
    "        if i not in vocab.keys():\n",
    "            vocab[i] = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662998a-ba5a-450d-b0f4-5865d55ef5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af69170-c158-418b-a1fb-68593a929bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('D:\\Transformers Implementation\\Language Model\\Data\\enwiki20201020\\\\00c2bfc7-57db-496e-9d5c-d62f8d8119e3.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79c6715-803c-44fa-8a07-f342408db61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sent = data[0]['text'].split('.')\n",
    "new_data = []\n",
    "for i in list_of_sent:\n",
    "    t = []\n",
    "    for k in i.split():\n",
    "        if k in vocab.keys():\n",
    "            t.append(vocab[k])\n",
    "    new_data.append(t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72bad670-37ae-42cb-b0e3-df8e53bd9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "mask_positions = []\n",
    "target_values = []\n",
    "weights = []\n",
    "new_sequences = []\n",
    "done_data = []\n",
    "for m, i in (enumerate(new_data)):\n",
    "    if len(i) > 5:\n",
    "        t = []\n",
    "        t_1 = []\n",
    "        t_2 = []\n",
    "        for k, j in enumerate(i):\n",
    "            if k < 20:\n",
    "                if random.random() <= 0.15:\n",
    "                    if len(t) < 3:\n",
    "                        t.append(k)\n",
    "                        t_1.append(j)\n",
    "                        t_2.append(1)\n",
    "                        i[k] = vocab['[MASK]']\n",
    "        weights.append(t_2 if len(t_2) == 3 else (\n",
    "            t_2 + [0]*(3-len(t_2))))\n",
    "        mask_positions.append(t if len(t) == 3 else (\n",
    "            t+[0]*(3-len(t_2))))\n",
    "        target_values.append(t_1 if len(t_1) == 3 else (\n",
    "            t_1+[0]*(3-len(t_1))))\n",
    "        new_sequences.append(\n",
    "            i[:20]+[0]*(20-len(i[:20])))\n",
    "\n",
    "done_data.append(({'tokens': new_sequences, 'mask_positions': mask_positions},\n",
    "                                          target_values, weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09028cb3-db69-4a71-bcd9-74909c7e4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    encoded_tokens = TransformerEncoder(vocab_size=len(vocab),\n",
    "        seq_len=20,\n",
    "        emb_dim=128,\n",
    "        linear_layers_hidden_dim = 128,\n",
    "        ffn_hiiden_dim = 128)\n",
    "    outputs = keras_nlp.layers.MLMHead(\n",
    "             activation=\"softmax\",vocabulary_size = len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682ab1d-e07e-425e-9109-0cb00b075ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98db1a-5659-441c-b00a-cc9c034490a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformers Kernel",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
